import os
import sys
import argparse
import glob
import time

import cv2
import numpy as np
from ultralytics import YOLO

# ---- ARDUINO SERIAL CONNECTION ----
import serial
try:
    arduino = serial.Serial('COM3', 9600, timeout=1)
    print("Arduino connected on COM3")
except:
    arduino = None
    print("WARNING: Arduino NOT connected")


# ----------------- ARGUMENT PARSER --------------------
parser = argparse.ArgumentParser()
parser.add_argument('--model', required=True,
                    help='Path to YOLO model file (example: "runs/detect/train/weights/best.pt")')
parser.add_argument('--source', required=True,
                    help='Source: image path, folder, video file, "usb0", etc.')
parser.add_argument('--thresh', default=0.5, help='Confidence threshold')
parser.add_argument('--resolution', default=None,
                    help='Resolution WxH (example: 1280x720)')
parser.add_argument('--record', action='store_true',
                    help='Record output video')

args = parser.parse_args()

model_path = args.model
img_source = args.source
min_thresh = float(args.thresh)
user_res = args.resolution
record = args.record

# Check if model exists
if not os.path.exists(model_path):
    print("ERROR: Model file not found!")
    sys.exit(0)

# Load YOLO model
model = YOLO(model_path)
labels = model.names

# Determine source type
img_ext = ['.jpg','.jpeg','.png','.bmp']
vid_ext = ['.mp4','.avi','.mov','.mkv','.wmv']

if os.path.isdir(img_source):
    source_type = 'folder'
elif os.path.isfile(img_source):
    _, ext = os.path.splitext(img_source)
    if ext.lower() in img_ext: source_type = 'image'
    elif ext.lower() in vid_ext: source_type = 'video'
    else:
        print("Unsupported file type")
        sys.exit(0)
elif 'usb' in img_source:
    source_type = 'usb'
    usb_idx = int(img_source.replace('usb', ''))
else:
    print("Invalid source")
    sys.exit(0)

# Resolution
resize = False
if user_res:
    resize = True
    resW, resH = map(int, user_res.split('x'))

# Recording
if record:
    if not user_res:
        print("Need resolution to record video.")
        sys.exit(0)
    recorder = cv2.VideoWriter("demo1.avi",
                               cv2.VideoWriter_fourcc(*"MJPG"),
                               30, (resW, resH))

# Prepare source
if source_type == 'image':
    imgs_list = [img_source]

elif source_type == 'folder':
    imgs_list = []
    for f in glob.glob(img_source + "/*"):
        _, ext = os.path.splitext(f)
        if ext.lower() in img_ext: imgs_list.append(f)

elif source_type == 'video':
    cap = cv2.VideoCapture(img_source)

elif source_type == 'usb':
    cap = cv2.VideoCapture(usb_idx)

    if resize:
        cap.set(3, resW)
        cap.set(4, resH)

# Colors for bounding box
bbox_colors = [
    (164,120,87), (68,148,228), (93,97,209), (178,182,133),
    (88,159,106), (96,202,231), (159,124,168), (169,162,241),
    (98,118,150), (172,176,184)
]

frame_rate_buffer = []
fps_avg_len = 200
avg_frame_rate = 0
img_count = 0


# ------------------------ MAIN LOOP --------------------------
while True:

    t_start = time.perf_counter()

    # Load source frame
    if source_type == 'image' or source_type == 'folder':
        if img_count >= len(imgs_list):
            print("All images processed.")
            sys.exit(0)
        frame = cv2.imread(imgs_list[img_count])
        img_count += 1

    elif source_type == 'video' or source_type == 'usb':
        ret, frame = cap.read()
        if not ret or frame is None:
            print("Video/Cam ended or error")
            break

    # Resize
    if resize:
        frame = cv2.resize(frame, (resW, resH))

    # YOLO detection
    results = model(frame, verbose=False)
    detections = results[0].boxes

    object_count = 0

    # Loop through detections
    for det in detections:

        xyxy = det.xyxy.cpu().numpy().squeeze()
        xmin, ymin, xmax, ymax = map(int, xyxy)

        classid = int(det.cls.item())
        classname = labels[classid]

        conf = det.conf.item()

        if conf >= min_thresh:

            color = bbox_colors[classid % len(bbox_colors)]
            cv2.rectangle(frame, (xmin,ymin), (xmax,ymax), color, 2)

            label = f"{classname}: {int(conf*100)}%"
            cv2.putText(frame, label, (xmin, ymin-5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

            object_count += 1

            # ---------- ARDUINO LOGIC ----------
            if classname == "Hello Partha":
                print(">>> Hello Partha detected!")

                if arduino:
                    arduino.write(b'1')
                    print("Sent 1 to Arduino")
            else:
                if arduino:
                    arduino.write(b'0')


    # FPS display
    cv2.putText(frame, f"FPS: {avg_frame_rate:.2f}", (10,20),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)

    cv2.imshow("YOLO detection results", frame)
    if record:
        recorder.write(frame)

    # Keyboard input
    key = cv2.waitKey(1)
    if key in [ord('q'), ord('Q')]:
        break
    if key in [ord('p'), ord('P')]:
        cv2.imwrite("capture.png", frame)

    # FPS calculation
    t_end = time.perf_counter()
    fps = 1 / (t_end - t_start)

    if len(frame_rate_buffer) >= fps_avg_len:
        frame_rate_buffer.pop(0)
    frame_rate_buffer.append(fps)
    avg_frame_rate = np.mean(frame_rate_buffer)


# Cleanup
print(f"Avg FPS: {avg_frame_rate:.2f}")
try:
    cap.release()
except:
    pass
cv2.destroyAllWindows()
if record:
    recorder.release()



